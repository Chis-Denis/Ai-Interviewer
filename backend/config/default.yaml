llm:
  base_url: "https://api.openai.com/v1"
  temperature: 0.7
  max_tokens: 2000

interview:
  max_questions: 5

prompts:
  version: "v1"
  templates_path: ""

cors:
  origins:
    - "http://localhost:5173"
    - "http://localhost:3000"